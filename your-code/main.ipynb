{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_csv('housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CRIM - per capita crime rate by town\n",
    "ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "INDUS - proportion of non-retail business acres per town.\n",
    "CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "NOX - nitric oxides concentration (parts per 10 million)\n",
    "RM - average number of rooms per dwelling\n",
    "AGE - proportion of owner-occupied units built prior to 1940\n",
    "DIS - weighted distances to five Boston employment centres\n",
    "RAD - index of accessibility to radial highways\n",
    "TAX - full-value property-tax rate per $10,000\n",
    "PTRATIO - pupil-teacher ratio by town\n",
    "B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "LSTAT - % lower status of the population\n",
    "MEDV - Median value of owner-occupied homes in $1000's\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"R² training {r2_train:.4f}\")\n",
    "print(f\"R² testing {r2_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "print(f\"MSE training{mse_train:.4f}\")\n",
    "print(f\"MSE testing{mse_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "# حساب متوسط الخطأ المطلق\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "print(f\"MAE training{mae_train:.4f}\")\n",
    "print(f\"MAE testing{mae_test:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# حساب متوسط الخطأ المطلق (MAE) لمجموعة التدريب\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# حساب متوسط الخطأ المطلق (MAE) لمجموعة الاختبار\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# طباعة القيم\n",
    "print(f\"MAE مجموعة التدريب: {mae_train:.4f}\")\n",
    "print(f\"MAE مجموعة الاختبار: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'],columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"data training {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"data testing  {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"The Logistic Regression model has been successfully trained!\")\n",
    "print(f\" {y_test_pred[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# التحقق من القيم الفريدة في y_train و y_train_pred\n",
    "print(\"Unique values in y_train:\", set(y_train))\n",
    "print(\"Unique values in y_train_pred:\", set(y_train_pred))\n",
    "\n",
    "# تحويل القيم المستمرة إلى فئات إذا لزم الأمر\n",
    "y_train_pred = y_train_pred.round()  # تقريب القيم للأقرب (للمسائل متعددة الفئات)\n",
    "y_test_pred = y_test_pred.round()\n",
    "\n",
    "# التأكد من أن الأبعاد متوافقة\n",
    "y_train_pred = y_train_pred.reshape(-1)\n",
    "y_test_pred = y_test_pred.reshape(-1)\n",
    "\n",
    "# حساب الدقة على بيانات التدريب والاختبار\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# طباعة النتائج\n",
    "print(f\"Model accuracy on training data: {train_accuracy:.4f}\")\n",
    "print(f\"Model accuracy on test data: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# التأكد من أن التوقعات صحيحة (تقريب القيم المستمرة إلى أقرب فئة)\n",
    "y_train_pred = y_train_pred.round()\n",
    "y_test_pred = y_test_pred.round()\n",
    "\n",
    "# إعادة تشكيل المصفوفات لتجنب الأخطاء\n",
    "y_train_pred = y_train_pred.reshape(-1)\n",
    "y_test_pred = y_test_pred.reshape(-1)\n",
    "\n",
    "# حساب الدقة المتوازنة\n",
    "train_balanced_accuracy = balanced_accuracy_score(y_train, y_train_pred)\n",
    "test_balanced_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# طباعة النتائج\n",
    "print(f\"Balanced accuracy on training data: {train_balanced_accuracy:.4f}\")\n",
    "print(f\"Balanced accuracy on test data: {test_balanced_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# التأكد من أن التوقعات صحيحة (تقريب القيم المستمرة إلى أقرب فئة)\n",
    "y_train_pred = y_train_pred.round()\n",
    "y_test_pred = y_test_pred.round()\n",
    "\n",
    "# إعادة تشكيل المصفوفات لتجنب الأخطاء\n",
    "y_train_pred = y_train_pred.reshape(-1)\n",
    "y_test_pred = y_test_pred.reshape(-1)\n",
    "\n",
    "# حساب الدقة الموزونة (هي نفسها balanced accuracy في بعض الحالات)\n",
    "train_weighted_accuracy = balanced_accuracy_score(y_train, y_train_pred)\n",
    "test_weighted_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# طباعة النتائج\n",
    "print(f\"Weighted accuracy on training data: {train_weighted_accuracy:.4f}\")\n",
    "print(f\"Weighted accuracy on test data: {test_weighted_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# التأكد من أن التوقعات صحيحة (تقريب القيم المستمرة إلى أقرب فئة)\n",
    "y_train_pred = y_train_pred.round()\n",
    "y_test_pred = y_test_pred.round()\n",
    "\n",
    "# إعادة تشكيل المصفوفات لتجنب الأخطاء\n",
    "y_train_pred = y_train_pred.reshape(-1)\n",
    "y_test_pred = y_test_pred.reshape(-1)\n",
    "\n",
    "# حساب درجة الاسترجاع\n",
    "train_recall = recall_score(y_train, y_train_pred, average=\"weighted\")\n",
    "test_recall = recall_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "# طباعة النتائج\n",
    "print(f\"Recall score on training data: {train_recall:.4f}\")\n",
    "print(f\"Recall score on test data: {test_recall:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# التأكد من أن التوقعات صحيحة (تقريب القيم المستمرة إلى أقرب فئة)\n",
    "y_train_pred = y_train_pred.round()\n",
    "y_test_pred = y_test_pred.round()\n",
    "\n",
    "# إعادة تشكيل المصفوفات لتجنب الأخطاء\n",
    "y_train_pred = y_train_pred.reshape(-1)\n",
    "y_test_pred = y_test_pred.reshape(-1)\n",
    "\n",
    "# حساب F1-score\n",
    "train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "# طباعة النتائج\n",
    "print(f\"F1-score on training data: {train_f1:.4f}\")\n",
    "print(f\"F1-score on test data: {test_f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# التأكد من أن القيم التنبؤية صحيحة (تقريب القيم المستمرة إلى أقرب فئة)\n",
    "y_train_pred = y_train_pred.round()\n",
    "y_test_pred = y_test_pred.round()\n",
    "\n",
    "# حساب مصفوفات الالتباس\n",
    "train_conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# طباعة النتائج النصية\n",
    "print(\"Confusion Matrix for Training Data:\")\n",
    "print(train_conf_matrix)\n",
    "print(\"\\nConfusion Matrix for Test Data:\")\n",
    "print(test_conf_matrix)\n",
    "\n",
    "# رسم مصفوفات الالتباس بشكل مرئي\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(train_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0])\n",
    "axes[0].set_title(\"Confusion Matrix (Training)\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "\n",
    "sns.heatmap(test_conf_matrix, annot=True, fmt=\"d\", cmap=\"Oranges\", ax=axes[1])\n",
    "axes[1].set_title(\"Confusion Matrix (Test)\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
